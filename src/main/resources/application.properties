server.port=8090
#基础的jdbc
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/data-spider?characterEncoding=utf-8&autoReconnect=true&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=GMT%2B8
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.username=root
spring.datasource.password=passw0rd@Y

#配置durid连接池
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.druid.initial-size=1
spring.datasource.druid.min-idle=1
spring.datasource.druid.maxActive=5
spring.datasource.druid.maxWait=60000
spring.datasource.druid.timeBetweenEvictionRunsMillis=60000
spring.datasource.druid.minEvictableIdleTimeMillis=300000
spring.datasource.druid.validationQuery=SELECT 1 FROM DUAL
spring.datasource.druid.testWhileIdle=true
spring.datasource.druid.testOnBorrow=false
spring.datasource.druid.testOnReturn=false
spring.datasource.druid.poolPreparedStatements=true
spring.datasource.druid.maxPoolPreparedStatementPerConnectionSize=20
#设置druid支持emoji表情
spring.datasource.druid.connection-init-sqls=set names utf8mb4
#stat是统计，wall是SQL防火墙，防SQL注入的，
#如果写输出统计数据的日志类型一定系统确实有的，比如系统用的log4j，但是你写log4j2，那就会报错
spring.datasource.druid.filters=stat,wall
spring.datasource.druid.connectionProperties=druid.stat.mergeSql\=true;druid.stat.slowSqlMillis\=5000

# WebStatFilter配置，监控统计用的filter:stat,如果没有配置filter信息。session监控，web监控等不可用。
#是否启用StatFilter默认值true
spring.datasource.druid.web-stat-filter.enabled=true
spring.datasource.druid.web-stat-filter.url-pattern=/*
spring.datasource.druid.web-stat-filter.session-stat-enable=true 
spring.datasource.druid.web-stat-filter.session-stat-max-count=100
#设置不统计哪些URL
spring.datasource.druid.web-stat-filter.exclusions=*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*

# StatViewServlet配置，防御sql注入的filter:wall,配置Druid Monitor信息
# 是否启用StatFilter默认值true，不开就会默认配置
spring.datasource.druid.stat-view-servlet.url-pattern=/druid/*
#spring.datasource.druid.stat-view-servlet.allow=127.0.0.1,192.168.163.1
#spring.datasource.druid.stat-view-servlet.deny=192.168.1.73
spring.datasource.druid.stat-view-servlet.reset-enable=false
spring.datasource.druid.stat-view-servlet.login-username=admin
spring.datasource.druid.stat-view-servlet.login-password=karakal

# Spring监控，对内部各接口调用的监控
spring.datasource.druid.aop-patterns=com.data.mapper.*,com.data.controller.*

# log 配置
logging.config=classpath:logback-spring.xml
logging.file.path=/logs
logging.level.com.data=info
logging.level.org.springframework.web=info
logging.level.org.apache.http=info
logging.level.us.codecraft.webmagic=info

#kafka配置
spring.kafka.producer.bootstrapServers=192.168.1.201:9092,192.168.1.202:9092,192.168.1.203:9092
spring.kafka.producer.retries=3
spring.kafka.listener.concurrency=3
#16K
spring.kafka.producer.batchSize=16384
spring.kafka.producer.lingerMs=1
#32M
spring.kafka.producer.bufferMemory=33554432

spring.kafka.consumer.bootstrapServers=192.168.1.201:9092,192.168.1.202:9092,192.168.1.203:9092
spring.kafka.consumer.groupId=group-spider
spring.kafka.consumer.enableAutoCommit=false
spring.kafka.consumer.autoCommitIntervalMs=1000
spring.kafka.consumer.sessionTimeoutMs=30000
spring.kafka.consumer.maxPollRecords=100
#earliest,latest
spring.kafka.consumer.autoOffsetReset=earliest


#topic名称
mq.topicName.checkIP=spider-topic-proxyIp
mq.topicName.douyin.video=spider-topic-douyin-video
mq.topicName.douyin.user.query=spider-topic-douyin-user-query


#定时任务执行频率
#每隔4分钟的第1秒检查数据库中的获取到的代理IP是否可用
task.checkProxyIp.schedule=1 */4 * * * ?
#每隔9分钟的第20秒调用一个爬虫获取可用的代理IP
task.xiciCrawlProxyIp.schedule=20 */9 * * * ?
#每隔19分钟的第40秒调用另一个爬虫获取可用的代理IP
task.kuaidailiCrawlProxyIp.schedule=40 */19 * * * ?

#每隔1分钟的第1秒检查是否有新的抖音抓包数据
task.scaner.resp.schedule=1 */1 * * * ?


#代理端口
proxy.server.port=8181
proxy.server.username=root
proxy.server.password=yangyboy


#抖音接口返回数据文件地址
scanner.douyin.respPath=/Users/yang/work/douyin-req/aweme-lq.snssdk.com/aweme/v1/search/item

#抖音根据sec_uid查询抖音用户信息接口地址
douyin.user.query=https://www.iesdouyin.com/web/api/v2/user/info/?sec_uid=
